{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating synthetic SAMUeL data  data with SMOTE\n",
    "\n",
    "## Description of SMOTE\n",
    "\n",
    "SMOTE stands for Synthetic Minority Oversampling Technique [1]. SMOTE is more commonly used to create additional data to enhance modelling fitting, especially when one or more classes have low prevalence in the data set. Hence the description of *oversampling*. \n",
    "\n",
    "SMOTE works by finding near-neighbor points in the original data, and creating new data points from interpolating between two near-neighbor points.\n",
    "\n",
    "Here we remove the real data used to create the synthetic data, leaving only the synthetic data. After generating synthetic data we remove any data points that, by chance, are identical to original real data points, and also remove 10% of points that are closest to the original data points. We measure 'closeness' by the Cartesian distance between standardised data values.\n",
    "\n",
    "![](./images/smote.png)\n",
    "\n",
    "*Demonstration of SMOTE method. (a) Data points with two features (shown on x and y axes) are represented. Points are colour-coded by class label. (b) A data point from a class is picked at random, shown by the black point, and then the closest neighbours of the same class are identified, as shown by yellow points. Here we show 3 closest neighbours, but the default in the SMOTE `Imbalanced-Learn` library is 6. One of those near-neighbour points is selected at random (shown by the second black point). A new data point, shown in red, is created at a random distance between the two selected data points.*\n",
    "\n",
    "### Handling integer, binary, and categorical data\n",
    "\n",
    "The standard SMOTE method generates floating point non-integer) values between data points. There are alternative ways of handing integer, binary, and categorical data using the SMOTE method. Here the methods we use are:\n",
    "\n",
    "* *Integer* values: Round the resulting synthetic data point value to the closest integer.\n",
    "\n",
    "* *Binary*: Code the value as 0 or 1, and round the resulting synthetic data point value to the closest integer (0 or 1).\n",
    "\n",
    "* *Categorical*: One-hot encode the categorical feature. Generate the synthetic data for each category value. Identify the category with the highest value and set to 1 while setting all others to 0.\n",
    "\n",
    "### Implementation with IMBLEARN\n",
    "\n",
    "Here use the implementation in the IMBLEARN IMBALANCED-LEARN [2] \n",
    "\n",
    "[1] Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P. “SMOTE: Synthetic minority over-sampling technique,” Journal of Artificial Intelligence Research, vol. 16, pp. 321-357, 2002.\n",
    "\n",
    "[2] Lemaitre, G., Nogueira, F. and Aridas, C. (2016), Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning. arXiv:1609.06570 (https://pypi.org/project/imbalanced-learn/, `pip install imbalanced-learn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Turn warnings off for notebook publication\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (k-fold split 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./../data/sam_1/kfold_5fold/train_0.csv')\n",
    "original_col_list = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(x):\n",
    "    \"\"\"\n",
    "    Takes a list/array/series and returns 1 for highest value and 0 for all \n",
    "    others\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get argmax\n",
    "    highest = np.argmax(x)\n",
    "    # Set all values to zero\n",
    "    x *= 0.0\n",
    "    # Set argmax to one\n",
    "    x[highest] = 1.0\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\n",
    "    'MoreEqual80y', \n",
    "    'S1Gender',\n",
    "    'S1Ethnicity',\n",
    "    'S1OnsetInHospital',\n",
    "    'S1OnsetTimeType',\n",
    "    'S1OnsetDateType',\n",
    "    'S1ArriveByAmbulance',\n",
    "    'S1AdmissionHour',\n",
    "    'S1AdmissionDay',\n",
    "    'S1AdmissionQuarter',\n",
    "    'S1AdmissionYear',\n",
    "    'CongestiveHeartFailure',\n",
    "    'Hypertension',\n",
    "    'AtrialFibrillation',\n",
    "    'Diabetes',\n",
    "    'StrokeTIA',\n",
    "    'AFAntiplatelet',\n",
    "    'AFAnticoagulentVitK',\n",
    "    'AFAnticoagulentDOAC',\n",
    "    'AFAnticoagulentHeparin',\n",
    "    'S2NewAFDiagnosis',\n",
    "    'S2StrokeType',\n",
    "    'S2TIAInLastMonth']\n",
    "\n",
    "X_col_names = list(data)\n",
    "one_hot_cols = []\n",
    "for col in col_list:\n",
    "    one_hot = [x for x in X_col_names if x[0:len(col)] == col]\n",
    "    one_hot_cols.append(one_hot)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_cols = [\n",
    "    'S1AgeOnArrival',\n",
    "    'S2RankinBeforeStroke',\n",
    "    'Loc',\n",
    "    'LocQuestions',\n",
    "    'LocCommands',\n",
    "    'BestGaze',\n",
    "    'Visual',\n",
    "    'FacialPalsy',\n",
    "    'MotorArmLeft',\n",
    "    'MotorArmRight',\n",
    "    'MotorLegLeft',\n",
    "    'MotorLegRight',\n",
    "    'LimbAtaxia',\n",
    "    'Sensory',\n",
    "    'BestLanguage',\n",
    "    'Dysarthria',\n",
    "    'ExtinctionInattention',\n",
    "    'S2NihssArrival']\n",
    "\n",
    "integer_min_max = dict()\n",
    "for col in integer_cols:\n",
    "    col_min = int(data[col].min())\n",
    "    col_max = int(data[col].max())\n",
    "    integer_min_max[col] = (col_min, col_max)\n",
    "    \n",
    "# Manually clip age to 30 - 100 to avoid using extremes\n",
    "integer_min_max['S1AgeOnArrival'] = (30, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesising 132 out of 132"
     ]
    }
   ],
   "source": [
    "synthetic_dfs = []\n",
    "\n",
    "groups = data.groupby('StrokeTeam') # creates a new object of groups of data\n",
    "count = 0 \n",
    "\n",
    "for index, group_df in groups: # each group has an index and a dataframe of data\n",
    "\n",
    "    count += 1\n",
    "    print (f'\\rSynthesising {count} out of {len(groups)}', end='')\n",
    "    \n",
    "    # Split data in X and y\n",
    "    X = group_df.drop(['S2Thrombolysis'], axis=1)\n",
    "    X.drop('StrokeTeam', inplace = True, axis=1)\n",
    "    y = group_df['S2Thrombolysis']\n",
    "    \n",
    "    X_col_names = list(X)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    # Count number in each class\n",
    "    count_label_0 = np.sum(y==0)\n",
    "    count_label_1 = np.sum(y==1)\n",
    "    \n",
    "    # Skip hospitals with fewer than 10 in either class\n",
    "    if min(count_label_0, count_label_1) < 10:\n",
    "        continue\n",
    "        \n",
    "    # Will make SMOTE data to be 2x original data\n",
    "    n_class_0 = 2 * count_label_0\n",
    "    n_class_1 = 2 * count_label_1\n",
    "\n",
    "    X_resampled, y_resampled = SMOTE(\n",
    "        sampling_strategy = {0:n_class_0, 1:n_class_1}).fit_resample(X, y)\n",
    "\n",
    "    # Get just synthetic data (ignore original data)\n",
    "    X_synthetic = X_resampled[len(X):]\n",
    "    y_synthetic = y_resampled[len(y):]\n",
    "        \n",
    "    # Reconstruct dataframe\n",
    "    df = pd.DataFrame(X_synthetic, columns=X_col_names)\n",
    "    df['S2Thrombolysis'] = y_synthetic\n",
    "    df['StrokeTeam'] = index\n",
    "    \n",
    "    # Make one hot as necessary\n",
    "    for one_hot_list in one_hot_cols:\n",
    "        for row_index, row in df.iterrows():\n",
    "            x = row[one_hot_list]\n",
    "            x_one_hot = make_one_hot(x)\n",
    "            row[x_one_hot.index] = x_one_hot.values\n",
    "            df.loc[row_index] = row\n",
    "    \n",
    "    # Round and clip integer columns\n",
    "    for col in integer_cols:\n",
    "        df[col] = df[col].round(0)\n",
    "        # Clip\n",
    "        df[col] = np.clip(\n",
    "            df[col], integer_min_max[col][0], integer_min_max[col][1])\n",
    "    \n",
    "    # Add to list\n",
    "    synthetic_dfs.append(df)\n",
    "    \n",
    "# Concatenate results and shuffle\n",
    "synthetic_data = pd.concat(synthetic_dfs)\n",
    "synthetic_data = synthetic_data.sample(frac=1.0)\n",
    "synthetic_data = synthetic_data[original_col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "filename = './../data/sam_1/kfold_5fold/synth_train_0.csv'\n",
    "synthetic_data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Other k-fold data sets are create in other notebooks running at the same time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
